https://blog.csdn.net/maopig/article/details/121357873
PCIE相关概念：
传输速率为每秒传输量GT/s，而不是每秒位数Gbps，因为传输量包括不提供额外吞吐量的开销位； 比如 PCIe 1.x和PCIe 2.x使用8b / 10b编码方案，导致占用了20% （= 2/10）的原始信道带宽。
GT/s ―― Giga transation per second （千兆传输/秒），即每一秒内传输的次数。重点在于描述物理层通信协议的速率属性，可以不和链路宽度等关联。
Gbps ―― Giga Bits Per Second （千兆位/秒）。GT/s 与Gbps 之间不存在成比例的换算关系。

PCIE带宽计算
PCIe 吞吐量（可用带宽）计算方法：

吞吐量 = 传输速率 *  编码方案

例如：PCI-e2.0 协议支持 5.0 GT/s，即每一条Lane 上支持每秒钟内传输 5G个Bit；但这并不意味着 PCIe 2.0协议的每一条Lane支持 5Gbps 的速率。
因为PCIe 2.0 的物理层协议中使用的是 8b/10b 的编码方案。 即每传输8个Bit，需要发送10个Bit；这多出的2个Bit并不是对上层有意义的信息。

那么， PCIe 2.0协议的每一条Lane支持 5 * 8 / 10 = 4 Gbps = 500 MB/s 的速率。
以一个PCIe 2.0 x8的通道为例，x8的可用带宽为 4 * 8 = 32 Gbps = 4 GB/s。

同理，
PCI-e3.0 协议支持 8.0 GT/s, 即每一条Lane 上支持每秒钟内传输 8G个Bit。
而PCIe 3.0 的物理层协议中使用的是 128b/130b 的编码方案。 即每传输128个Bit，需要发送130个Bit。
那么， PCIe 3.0协议的每一条Lane支持 8 * 128 / 130 = 7.877 Gbps = 984.6 MB/s 的速率。
一个PCIe 3.0 x16的通道，x16 的可用带宽为 7.877 * 16 = 126.031 Gbps = 15.754 GB/s。


https://blog.csdn.net/kunkliu/article/details/109469800?spm=1001.2101.3001.6650.3&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-3.pc_relevant_antiscanv2&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-3.pc_relevant_antiscanv2&utm_relevant_index=6

PCIe是串行总线，PCIe1.0的线上比特传输速率为2.5Gb/s，物理层使用8/10编码，即8比特的数据，实际在物理线路上是需要传输10比特的，因此：

PCIe1.0 x 1的带宽=（2.5Gb/s x 2（双向通道））/ 10bit = 0.5GB/s
这是单条Lane的带宽，有几条Lane，那么整个带宽就0.5GB/s乘以Lane的数目。

PCIe2.0的线上比特传输速率在PCIe1.0的基础上翻了一倍，为5Gb/s，物理层同样使用8/10编码，所以：
PCIe2.0 x 1的带宽=（5Gb/s x 2（双向通道））/ 10bit = 1GB/s
同样，有多少条Lane，带宽就是1GB/s乘以Lane的数目。

PCIe3.0的线上比特传输速率没有在PCIe2.0的基础上翻倍，不是10Gb/s，而是8Gb/s，但物理层使用的是128/130编码进行数据传输，所以：
PCIe3.0 x 1的带宽=（8Gb/s x 2（双向通道））/ 8bit = 2GB/s
同样，有多少条Lane，带宽就是2GB/s乘以Lane的数目。

由于采用了128/130编码，128比特的数据，只额外增加了2bit的开销，有效数据传输比率增大，虽然线上比特传输率没有翻倍，但有效数据带宽还是在PCIe2.0的基础上做到翻倍。

这里值得一提的是，上面算出的数据带宽已经考虑到8/10或者128/130编码，因此，大家在算带宽的时候，没有必要再考虑线上编码的问题了。


PCIe3.0x4理论上最大的4K IOPS。PCIe3.0x4理论最大读或者写的速度为4GB/s，不考虑协议开销，每秒可以传输4GB/4K个4K大小的IO，该值为1M，即理论上最大IOPS为1000K。因此，一个SSD，不管你底层用什么介质，flash还是3d xpoint，接口速度就这么块，最大IOPS是不可能超过这个值的。
PCIe是从PCI发展过来的，PCIe的”e”是express的简称，快的意思
在实际时钟频率比较低的情况下，并口因为可以同时传输若干比特，速率确实比串口快。随着技术的发展，数据传输速率要求越来越快，要求时钟频率也越来越快，但是，并行总线时钟频率不是想快就能快的。

在发送端，数据在某个时钟沿传出去（左边时钟第一个上升沿），在接收端，数据在下个时钟沿（右边时钟第二个上升沿）接收。因此，要在接收端能正确采集到数据，要求时钟的周期必须大于数据传输的时间（从发送端到接收端，flight time)。受限于数据传输时间（该时间还随着数据线长度的增加而增加），因此时钟频率不能做得太高。
另外，时钟信号在线上传输的时候，也会存在相位偏移（clock skew )，影响接收端的数据采集；还有，并行传输，接收端必须等最慢的那个bit数据到了以后，才能锁住整个数据 （signal skew）。

和SATA单通道不同，PCIe连接可以通过增加通道数扩展带宽，弹性十足。通道数越多，速度越快。不过，通道数越多，成本越高，占用更多空间，还有就是更耗电。因此，使用多少通道，应该在性能和其他因素之间进行一个综合考虑。单考虑性能的话，PCIe最高带宽可达64GB/s，PCIe 3.0 x 32对应的带宽，很恐怖的一个数据。
不过，现有的PCIe接口SSD，一般最多使用4通道，如PCIe3.0x4，双向带宽为8GB/s，读或者写带宽为4GB/s。


PCIe使用串行总线进行数据传输就没有这些问题。它没有外部时钟信号，它的时钟信息通过8/10编码或者128/130编码嵌入在数据流，接收端可以从数据流里面恢复时钟信息，因此，它不受数据在线上传输时间的限制，你导线多长都没有问题，你数据传输频率多快也没有问题；没有外部时钟信号，自然就没有所谓的clock skew问题；由于是串行传输，只有一个bit传输，所以不存在signal skew问题。
但是，如果使用多条lane传输数据（串行中又有并行），这个问题又回来了，因为接收端同样要等最慢的那个lane上的数据到达才能处理整个数据。

